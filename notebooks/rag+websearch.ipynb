{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG + web search + crewAI\n",
    "\n",
    "In this notebook I've used a Vector Database retriever (from Qdrant ) to retrieve information from Qdrant DB and feed them to the crew's writer that will produce the final output . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.linkedin.com/pulse/agentic-rag-using-crewai-langchain-pavan-belagatti-ewwsc/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection test already exists!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-28 16:12:30,568 - 132595631763456 - __init__.py-__init__:538 - WARNING: Overriding of current TracerProvider is not allowed\n",
      "2024-10-28 16:12:30,689 - 132595631763456 - __init__.py-__init__:538 - WARNING: Overriding of current TracerProvider is not allowed\n",
      "2024-10-28 16:12:30,693 - 132595631763456 - __init__.py-__init__:538 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import os\n",
    "from crewai_kit.crews import rag_crew\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs ={\"question\":\"How does self-attention mechanism help large language models?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRouter\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mAnalyse the keywords in the question How does self-attention mechanism help large language models?Based on the keywords decide whether it is eligible for a vectorstore search or a web search.Return a single word 'vectorstore' if it is eligible for vectorstore search.Return a single word 'websearch' if it is eligible for web search.Do not provide any other premable or explaination.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRouter\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: The question \"How does self-attention mechanism help large language models?\" is related to the concept of attention mechanisms in language models, which is suitable for a vectorstore search.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mRouter Function\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"question\\\": \\\"How does self-attention mechanism help large language models?\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "vectorstore\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRouter\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "vectorstore\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRetriever\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mBased on the response from the router task extract information for the question How does self-attention mechanism help large language models? with the help of the respective tool.Use the web_serach_tool to retrieve information from the web in case the router task output is 'websearch'.Use the rag_tool to retrieve information from the vectorstore in case the router task output is 'vectorstore'.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mRetriever\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "The self-attention mechanism helps large language models by allowing the model to weigh the importance of different words in a sentence when processing information. This mechanism enables the model to focus on relevant parts of the input sequence, capturing long-range dependencies effectively and improving the model's performance in understanding and generating language.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAnswer Grader\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mBased on the response from the retriever task for the quetion How does self-attention mechanism help large language models? evaluate whether the retrieved content is relevant to the question.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAnswer Grader\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "no\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mHallucination Grader\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mBased on the response from the grader task for the quetion How does self-attention mechanism help large language models? evaluate whether the answer is grounded in / supported by a set of facts.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mHallucination Grader\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "no\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAnswer Grader\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mBased on the response from the hallucination task for the quetion How does self-attention mechanism help large language models? evaluate whether the answer is useful to resolve the question.If the answer is 'yes' return a clear and concise answer.If the answer is 'no' then perform a 'websearch' and return the response\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mAnswer Grader\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "The self-attention mechanism helps large language models by allowing them to weigh the importance of different words in a sentence, capturing long-range dependencies effectively.\u001b[00m\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = rag_crew.kickoff(inputs=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################\n",
      "The self-attention mechanism helps large language models by allowing them to weigh the importance of different words in a sentence, capturing long-range dependencies effectively.\n"
     ]
    }
   ],
   "source": [
    "print(\"######################\")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crewaiv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
